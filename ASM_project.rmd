---
output:
  pdf_document:
    toc: false
    number_sections: false
    toc_depth: 1
  html_document:
    toc: false
    toc_depth: '1'
    df_print: paged
editor_options:
  chunk_output_type: console
---

\begin{titlepage}
    \centering
    \includegraphics[width=\textwidth]{UPC.jpg}
    \vfill
    {\Huge \textbf{ASM - Time Series Project}} \\[1.5cm]
    \vfill
    {\Large Authors: Dmitriy Chukhray, Julian Fransen} \\[0.5cm]
    {\Large Date: 2025-01-06}
\end{titlepage}

\newpage
\tableofcontents
\newpage

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
#setwd("~/uni_folder/ASM/asm_time_series/")
```

# Introduction
The dataset under analysis consists of monthly data on victims of traffic accidents in Spain, including fatalities, serious injuries, and minor injuries, recorded on urban and interurban roads. In this project we will apply the Box-Jenkins ARIMA methodology to understand the time-series dynamics of these traffic incidents and to make reliable predictions for future trends. Spanning from 1993 to 2019, the dataset captures over two decades of detailed information, offering a unique opportunity to identify trends, seasonal patterns, and underlying factors that influence traffic accidents.

# 1. Identification

First, we load the raw data set and plot it to get a first impression of the data. Based on this, we will start with the identification of transformations.

```{r, echo=FALSE}
par(mfrow=c(1,1))
serie=ts(read.table("victimas.dat")/1000,start=1993,freq=12)
plot(serie, main="Victimas de Accidentes de Tráfico en España", ylab="Miles de Individuos")
abline(v=1992:2020,lty=3,col=4)
```

\newpage

## 1a. Data transformations

The first step in time series analysis is to check whether transformations are necessary to stabilize variance or remove trends.
We start by checking if the data shows constant variance over time. This is important because ARIMA models assume that the variance is constant. To do this, we compute the mean and variance for each year and examine their relationship. 
Additionally, we visualize yearly boxplots to confirm constant variance over time. 

```{r, include=FALSE}
(m <- apply (matrix(serie[1:(27*12)], nr=12),2, mean)) # to check for constant variance
(v <- apply (matrix(serie[1:(27*12)], nr=12),2, var))
```
```{r, echo=FALSE}
par(mfrow=c(1,1))
plot(v~m, main = "Check of constant variance (variance ~ mean)")
abline(lm(v~m),col=2,lty=3)

group <- c(rep(1:27, rep(12, 27)))
boxplot(serie ~ group,
        xlab = "Year",
        ylab = "Monthly values",
        main = "Check of constant variance (yearly boxplots)")
```

These plots show correct behaviour: `v` is basically uncorrelated with `m`, and the boxplots are similarly sized, implying constant variance. This means that a log transform is not necessary in our case. The next step is to check the existence of a seasonal pattern in the time series. To do that we are using the function `monthplot`.

```{r, echo=FALSE}
monthplot(serie, main = "Seasonal Patterns in Traffic Accident Data")
```

In the plot above, we can clearly observe a seasonal pattern. If there were no seasonal component, the monthly means would remain at approximately the same level over time, and the shapes of the patterns for each month would not exhibit systematic repetition. These periodic fluctuations suggest that certain months consistently experience higher or lower values, driven by underlying seasonal component(s). To account for this seasonality, we apply a seasonal differencing transformation with a yearly period (12 months).

```{r, echo=FALSE}
d12serie=diff(serie,12)
plot(d12serie, main = "After seasonality transformation")
abline(h=0, col='red', lty=2)
```

The last step of achieving the stationary of the time series is to check whether the mean is constant or not. This can be done by examining the plot of the current time series data or by straight forwardly applying regular difference and then examining the change of the time series' variance.

```{r, echo=FALSE}
d1d12serie=diff(d12serie,1)
```

To verify if taking one regular difference is optimal, we calculate the variance of different transformation of the data:
```plaintext
1. original data (`serie`)
2. transformed with yearly season transformation (`d12serie`)
3. one regular difference applied to the previous transformation (`d1d12serie`)
4. another regular difference applied to the previous transformation
```

The values are here below:

```{r, echo=FALSE}
# Calculate variances for different transformations
var_original = var(serie)
var_seasonal_diff = var(d12serie)
var_regular_diff = var(d1d12serie)
var_two_regular_diff = var(diff(d1d12serie))

# Output the variances
cat("Variance of original data:", var_original, "\n")
cat("Variance after seasonal differencing:", var_seasonal_diff, "\n")
cat("Variance after one regular differencing:", var_regular_diff, "\n")
cat("Variance after two regular differencing:", var_two_regular_diff, "\n")

```

The total variance is minimal for one regular and one 12 month seasonal difference. This means that we should take one regular difference and no more. As we can see below, the data after transformations resembles white noise, which is the aim of data transformations in time-series data analysis. Now that we have stationary time series, we can propose ARIMA models by evaluating - among other metrics - the ACF and PACF plots.

```{r, echo=FALSE}
plot(d1d12serie, main = "Transformed data") 
abline(h=0, col='red', lty=2)
```

```{r, include=FALSE}
tserie <- d1d12serie #transformed serie is new name
```

\newpage

## 1b.

Now we are going to take a closer look at the ACF and the PACF plots. 

```{r, echo=FALSE}
par(mfrow=c(1,2))
acf(tserie,ylim=c(-1,1),col=c(2,rep(1,11)),lwd=2,lag.max=84)
pacf(tserie,ylim=c(-1,1),col=c(rep(1,11),2),lwd=2,lag.max=84)
```

To propose SARIMA models we need to evaluate ACF and PACF plots separately.
SARIMA model can be expressed as:

$$
SARIMA(p, d, q)(P, D, Q)_{s}
$$

Where:
\begin{itemize}
    \item \( p, d, q \): Non-seasonal AR, differencing, and MA terms, respectively.
    \item \( P, D, Q \): Seasonal AR, differencing, and MA terms, respectively.
    \item \( s \): Periodicity of the seasonal component.
\end{itemize}



Looking at the ACF plot we can clearly see decaying trend of non-seasonal lags after the lag 1, which is the biggest lag for the whole non-seasonal part and the subsequent lag experienced a sharp decline in ACF value hinting at possible MA(1) model (parameter q = 1). The same things can be said about seasonal lags in the ACF plot. There is a decaying trend of seasonal lags after the seasonal lag 1, which is the biggest seasonal lag for the whole seasonal part and the subsequent seasonal lag experienced a sharp decline in ACF value hinting at possible MA(1) model (parameter Q = 1). Now we move on to the PACF plot, which looks more complex than usual. The clearer trend is seen in seasonal lags of the PACF. The first seasonal lag is the biggest seasonal lag for the whole seasonal part and the subsequent seasonal lag experienced a sharp decline in PACF value hinting at possible AR(1) model (parameter P = 1). Here this trend is clearer than in the case of seasonal lags in the ACF because after seasonal lag 4 values become small so that exceeding confidence intervals becomes nearly impossible. In the ACF plot we have seen some seasonal lags being slightly above confidence intervals even though their antecedent lags were way below confidence intervals. The proposal of non-seasonal AR models by solely looking at the PACF plot in this particular case seems non-trivial, hence it would be a good idea to propose several hypothetical non-seasonal AR models and later check them using several model validation techniques. The decaying trend of non-seasonal AR part is there, though it is slower and seems to start later comparing it to non-seasonal MA part. Therefore, one could argue that one possible non-seasonal AR model which is AR(2) (parameter p = 2) because lag 2 is followed a lag that has experienced a sharp decline in PACF value. However, lags 4,5, and 6 are definitely above confidence intervals. Here is where we can propose another non-seasonal AR mode which is AR(6) (parameter p = 6), because lag 6 is followed by lags that are below confidence intervals consequentially and the decline in their values is sharper. Regarding the values of parameters d and D, we don't need to propose them because we know the actual values which are d = 1 and D = 1. In the end, combining everything we have seen we can propose 9 SARIMA models in the order of increasing complexity, which are:

\includegraphics[width=\textwidth]{models.png}

```{r, include=FALSE}
#################Validation#################################
validation=function(model){
  s=frequency(get(model$series))
  resid=model$residuals
  par(mfrow=c(2,2),mar=c(3,3,3,3))
  #Residuals plot
  plot(resid,main="Residuals")
  abline(h=0)
  abline(h=c(-3*sd(resid),3*sd(resid)),lty=3,col=4)
  #Square Root of absolute values of residuals (Homocedasticity)
  scatter.smooth(sqrt(abs(resid)),main="Square Root of Absolute residuals",
                 lpars=list(col=2))
  
  #Normal plot of residuals
  qqnorm(resid)
  qqline(resid,col=2,lwd=2)
  
  ##Histogram of residuals with normal curve
  hist(resid,breaks=20,freq=FALSE)
  curve(dnorm(x,mean=mean(resid),sd=sd(resid)),col=2,add=T)
  
  
  #ACF & PACF of residuals
  par(mfrow=c(1,2))
  acf(resid,ylim=c(-1,1),lag.max=60,col=c(2,rep(1,s-1)),lwd=1)
  pacf(resid,ylim=c(-1,1),lag.max=60,col=c(rep(1,s-1),2),lwd=1)
  par(mfrow=c(1,1))
  
  #Ljung-Box p-values
  par(mar=c(2,2,1,1))
  tsdiag(model,gof.lag=7*s)
  cat("\n--------------------------------------------------------------------\n")
  print(model)
  
  #Stationary and Invertible
  cat("\nModul of AR Characteristic polynomial Roots: ", 
      Mod(polyroot(c(1,-model$model$phi))),"\n")
  cat("\nModul of MA Characteristic polynomial Roots: ",
      Mod(polyroot(c(1,model$model$theta))),"\n")
  
  suppressMessages(require(forecast,quietly=TRUE,warn.conflicts=FALSE))
  plot(model)
  
  #Model expressed as an MA infinity (psi-weights)
  psis=ARMAtoMA(ar=model$model$phi,ma=model$model$theta,lag.max=36)
  names(psis)=paste("psi",1:36)
  cat("\nPsi-weights (MA(inf))\n")
  cat("\n--------------------\n")
  print(psis[1:24])
  
  #Model expressed as an AR infinity (pi-weights)
  pis=-ARMAtoMA(ar=-model$model$theta,ma=-model$model$phi,lag.max=36)
  names(pis)=paste("pi",1:36)
  cat("\nPi-weights (AR(inf))\n")
  cat("\n--------------------\n")
  print(pis[1:24])
   
  cat("\nDescriptive Statistics for the Residuals\n")
  cat("\n----------------------------------------\n") 
  
  suppressMessages(require(fBasics,quietly=TRUE,warn.conflicts=FALSE))
  ##Anderson-Darling test
  print(basicStats(resid))
  
  ## Add here complementary tests (use with caution!)
  ##---------------------------------------------------------
  cat("\nNormality Tests\n")
  cat("\n--------------------\n")
 
  ##Shapiro-Wilks Normality test
  print(shapiro.test(resid))

  suppressMessages(require(nortest,quietly=TRUE,warn.conflicts=FALSE))
  ##Anderson-Darling test
  print(ad.test(resid))
  
  suppressMessages(require(tseries,quietly=TRUE,warn.conflicts=FALSE))
  ##Jarque-Bera test
  print(jarque.bera.test(resid))
  
  cat("\nHomoscedasticity Test\n")
  cat("\n--------------------\n")
  suppressMessages(require(lmtest,quietly=TRUE,warn.conflicts=FALSE))
  ##Breusch-Pagan test
  obs=get(model$series)
  print(bptest(resid~I(obs-resid)))
  
  cat("\nIndependence Tests\n")
  cat("\n--------------------\n")
  
  ##Durbin-Watson test
  print(dwtest(resid~I(1:length(resid))))
  
  ##Ljung-Box test
  cat("\nLjung-Box test\n")
  print(t(apply(matrix(c(1:4,(1:4)*s)),1,function(el) {
    te=Box.test(resid,type="Ljung-Box",lag=el)
    c(lag=(te$parameter),statistic=te$statistic[[1]],p.value=te$p.value)})))
  
}
################# Fi Validation #################################
```

Below is the same data given in a more tabular manner.

```{r, echo=FALSE}
# Initialize a data frame to store the results
results <- data.frame(p = integer(),
                      i = integer(),
                      q = integer(),
                      P = integer(),
                      D = integer(),
                      Q = integer(),
                      AIC = numeric(),
                      BIC = numeric())


# Loop over possible values of P, D, Q, and period
for (p in c(0,2,6)) {          # Experiment with seasonal AR orders (e.g., 0 to 2)
  for (P in c(0,1)) {        # Seasonal differencing (typically 0 or 1)
     for (Q in 0:1) {     # Experiment with seasonal MA orders (e.g., 0 to 2)
      

        # Fit the ARIMA model with the current seasonal parameters
        mod <- arima(serie, 
                     order = c(p, 1, 1), 
                     seasonal = list(order = c(P,1,Q), period = 12))

        # Store the AIC and BIC values
        results <- rbind(results, 
                            data.frame(p = p,
                                    i = 1,
                                    q = 1,
                                    P = P,
                                    D = 1,
                                    Q = Q, 
                                    AIC = AIC(mod), 
                                    BIC = BIC(mod)))
     }
  }
}

# Sort results by AIC (or BIC) for easier interpretation
dresults <- results[order(results$AIC), ]
# Display the results
print(dresults)
```

From the output above we can state that our theory about possible non-seasonal AR(6) model might be correct. Some of the SARIMA models that have non-seasonal AR(6) part do very well in terms of AIC values, in fact the model SARIMA(6,1,1)(0,1,1)<sub>12</sub> has the lowest AIC value, however BIC penalizes complexity of the models differently than AIC does and in terms of BIC values these models are average at best. One might think that we should easily choose models that would have AIC values of 2-3 points higher but with BIC values of 10 points lower at worst that the earlier mentioned SARIMA models but AIC/BIC values is not the only indicator of selecting the most optimal time-series model. After experimenting with the proposed `p`, `P`, `Q` parameters for SARIMA models, we have decided to further validate 3 better than average models. These 3 models, `mod1`, `mod2`, and `mod3`, can be seen in the outputs above. Their value of `p` is different (6,2,0) but all other parameters are identical. We were thinking about inclusion of models that have seasonal AR part with the value of 1 (P = 1) but all such models always do worse in terms of AIC/BIC compared to exactly same models but with seasonal AR part with the value of 0 (P = 0). The first model `mod1` is the most complex in terms of parameters (the highest p parameter), it has the lowest AIC, and the highest BIC. The second model `mod2` is the 2nd ranked in terms of complexity of parameters (the second highest p parameter) and it has the second highest AIC and BIC. The third model `mod3` is the least complex in terms of parameters (the lowest p parameter), it has the highest AIC, and the lowest BIC.

# 2. Estimation

Based on the previous analyisi, we decide to investigate three model and below are the coeficients and other information about the models.

## 2a. 
```{r, echo=FALSE}
(mod1=arima(serie,order=c(6,1,1),seasonal=list(order=c(0,1,1),period=12)))
(mod2=arima(serie,order=c(2,1,1),seasonal=list(order=c(0,1,1),period=12)))
(mod3=arima(serie,order=c(0,1,1),seasonal=list(order=c(0,1,1),period=12)))
```


# 3. Validation

Now we will validate the proposed models, based on a thorough statistical anaylysis.

## 3a and 3b. 
We will be taking a look at the outputs of the validation function for models `mod1`, `mod2`, and `mod3`. This function provides all the necessary things for the evaluation of a model which are complete analysis of residuals and roots of polynomials/pi and psi weights to check the causality and/or invertibility. 

```{r}
validation(mod1)
```

For the model SARIMA(6,1,1)(0,1,1)<sub>12</sub>

- Residuals plot
    - The residuals are centered around zero with no evident trend
    - Occasional spikes above the confidence intervals that might be explain by potential outliers
- Square Root of Absolute Residuals
    - A reasonable consistent spread, which implies constant variance over time and homoscedasticity
- Normal Q-Q Plot
    - Small deviations from the diagonal line are seen at the ends of the line, but since the trend holds and deviations clearly can't be called heavy tails they might be caused by potential outliers
- Histogram of residuals
    - Some asymmetry is visible
    - A couple of observations above the bell-shaped curve are seen at the ends of it hinting at potential outliers
- ACF and PACF of Residuals
    - There are barely any lags that are above confidence intervals and if they are they are higher by negligible value indicating there are no significant autocorrelation/partial autocorrelations in residuals
- Standardized Residuals
    - The standardized residuals fluctuate around zero without evident patterns or trends, though some standardized residuals definitely look like spikes hinting at potential outliers
- p-values for Ljung-Box Test
    - None of the p-values for the Ljung-Box test are below 0.05, indicating no significant autocorrelation in the residuals.
    
Based on the SARIMA(6,1,1)(0,1,1)<sub>12</sub> model modules of AR/MA characteristic polynomial roots we can say that the model is both causal and invertible as all modules of polynomial roots are higher than 1.


```{r}
validation(mod2)
```

For the model SARIMA(2,1,1)(0,1,1)<sub>12</sub>

- Residuals plot
    - The residuals are centered around zero with no evident trend
    - Occasional spikes above the confidence intervals that might be explain by potential outliers
- Square Root of Absolute Residuals
    - A reasonable consistent spread, which implies constant variance over time and homoscedasticity
- Normal Q-Q Plot
    - Small deviations from the diagonal line are seen at the ends of the line, but since the trend holds and deviations clearly can't be called heavy tails they might be caused by potential outliers
    - Points at both ends of the lined distributed worse compared to SARIMA(6,1,1)(0,1,1)<sub>12</sub> model
    - Even though they are most likely called by potential outliers it means that skewness and kurtosis values might be different for this model compared to SARIMA(6,1,1)(0,1,1)<sub>12</sub> model
- Histogram of residuals
    - Some asymmetry is visible
    - A couple of observations above the bell-shaped curve are seen at the ends of it hinting at potential outliers
- ACF and PACF of Residuals
    - There are barely any lags that are above confidence intervals and if they are they are higher by negligible value indicating there are no significant autocorrelation/partial autocorrelations in residuals
- Standardized Residuals
    - The standardized residuals fluctuate around zero without evident patterns or trends, though some standardized residuals definitely look like spikes hinting at potential outliers
- p-values for Ljung-Box Test
    - None of the p-values for the Ljung-Box test are below 0.05 and the lowest p-value is around 0.0525, indicating no significant autocorrelation in the residuals.
    - Compared to SARIMA(6,1,1)(0,1,1)<sub>12</sub> model all p-values are significantly lower across the board, though they are still above the confidence interval
    
Based on the SARIMA(2,1,1)(0,1,1)<sub>12</sub> model modules of AR/MA characteristic polynomial roots we can say that the model is both causal and invertible as all modules of polynomial roots are higher than 1.


```{r}
validation(mod3)
```

For the model SARIMA(0,1,1)(0,1,1)<sub>12</sub>

- Residuals plot
    - The residuals are centered around zero with no evident trend
    - Occasional spikes above the confidence intervals that might be explain by potential outliers
- Square Root of Absolute Residuals
    - A reasonable consistent spread, which implies constant variance over time and homoscedasticity
- Normal Q-Q Plot
    - Small deviations from the diagonal line are seen at the ends of the line, but since the trend holds and deviations clearly can't be called heavy tails they might be caused by potential outliers
    - SARIMA(0,1,1)(0,1,1)<sub>12</sub> model has the best Normal Q-Q plot
- Histogram of residuals
    - Some asymmetry is visible
    - A couple of observations above the bell-shaped curve are seen at the ends of it hinting at potential outliers
- ACF and PACF of Residuals
    - There are barely any lags that are above confidence intervals and if they are they are higher by negligible value indicating there are no significant autocorrelation/partial autocorrelations in residuals
- Standardized Residuals
    - The standardized residuals fluctuate around zero without evident patterns or trends, though some standardized residuals definitely look like spikes hinting at potential outliers
- p-values for Ljung-Box Test
    - Around 50% of the p-values for the Ljung-Box test are below 0.05 and the lowest p-value is around close to 0 (somewhere around 0.01-0.02)
    - For the most part p-values struggle to be above 0.05 for higher lags indicating significant serial autocorrelation
    
Based on the SARIMA(0,1,1)(0,1,1)<sub>12</sub> model modules of AR/MA characteristic polynomial roots we can say that the model is both causal and invertible as all modules of polynomial roots are higher than 1.


## 3c.
Now we are going to check the stability of the proposed models and evaluate their capability of prediction, reserving the last 12 observations.


```{r, echo = FALSE, results = "hide", message = FALSE, warning = FALSE}
# Correct split for training and testing
ultim <- c(2018, 12)  # Train until the end of 2018
serie_train <- window(serie, end = ultim)  # Training data (1993 to 2018)
serie_test <- window(serie, start = ultim + c(0, 1))  # Test data (2019)

# Fit models to training data
(mod1B <- arima(serie_train, order = c(6, 1, 1), seasonal = list(order = c(0, 1, 1), period = 12)))
(mod2B <- arima(serie_train, order = c(2, 1, 1), seasonal = list(order = c(0, 1, 1), period = 12)))
(mod3B <- arima(serie_train, order = c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = 12)))

# Predict for the next 12 months (2019)
pred1 <- predict(mod1B, n.ahead = 12)
pred2 <- predict(mod2B, n.ahead = 12)
pred3 <- predict(mod3B, n.ahead = 12)

# Convert predictions and standard errors into time series
pr1 <- ts(pred1$pred, start = ultim + c(0, 1), freq = 12)
se1 <- ts(pred1$se, start = ultim + c(0, 1), freq = 12)
pr2 <- ts(pred2$pred, start = ultim + c(0, 1), freq = 12)
se2 <- ts(pred2$se, start = ultim + c(0, 1), freq = 12)
pr3 <- ts(pred3$pred, start = ultim + c(0, 1), freq = 12)
se3 <- ts(pred3$se, start = ultim + c(0, 1), freq = 12)

# Compute confidence intervals for predictions
tl1 <- pr1 - 1.96 * se1
tu1 <- pr1 + 1.96 * se1
tl2 <- pr2 - 1.96 * se2
tu2 <- pr2 + 1.96 * se2
tl3 <- pr3 - 1.96 * se3
tu3 <- pr3 + 1.96 * se3

# Evaluate Prediction Errors (2019 Observations)
obs <- window(serie, start = ultim + c(0, 1))  # Observed data for 2019
error1 <- obs - window(pr1, start = ultim + c(0, 1))
error2 <- obs - window(pr2, start = ultim + c(0, 1))
error3 <- obs - window(pr3, start = ultim + c(0, 1))

# Compute Metrics for Each Model
metrics <- data.frame(
  Model = c("ARIMA(6,1,1)(0,1,1)", "ARIMA(2,1,1)(0,1,1)", "ARIMA(0,1,1)(0,1,1)"),
  RMSE = c(sqrt(mean(error1^2, na.rm = TRUE)),
           sqrt(mean(error2^2, na.rm = TRUE)),
           sqrt(mean(error3^2, na.rm = TRUE))),
  MAE = c(mean(abs(error1), na.rm = TRUE),
          mean(abs(error2), na.rm = TRUE),
          mean(abs(error3), na.rm = TRUE)),
  RMSPE = c(sqrt(mean((error1 / obs)^2, na.rm = TRUE)),
            sqrt(mean((error2 / obs)^2, na.rm = TRUE)),
            sqrt(mean((error3 / obs)^2, na.rm = TRUE))),
  MAPE = c(mean(abs(error1 / obs), na.rm = TRUE),
           mean(abs(error2 / obs), na.rm = TRUE),
           mean(abs(error3 / obs), na.rm = TRUE))
)

# Display Metrics
metrics
```

```{r, echo = FALSE}
# Visualize predictions for Model 1 with Actual Data
plot(serie, xlim = c(2017, 2020), ylim = range(c(tl1, tu1, serie)),
     type = "o", col = 1, lty = 1, ylab = "Values", xlab = "Time",
     main = paste("Model ARIMA(6,1,1)(0,1,1)12"), xaxt = "n")
lines(pr1, col = 2, lty = 1, type = "o")
lines(tl1, col = 4, lty = 2)
lines(tu1, col = 4, lty = 2)
axis(1, at = c(2017, 2018, 2019, 2020), labels = c("2017", "2018", "2019", "2020"))
abline(v = c(2017, 2018, 2019, 2020), lty = 3, col = 4)

# Visualize predictions for Model 2
plot(serie, xlim = c(2017, 2020), ylim = range(c(tl2, tu2, serie)),
     type = "o", col = 1, lty = 1, ylab = "Values", xlab = "Time",
     main = paste("Model ARIMA(2,1,1)(0,1,1)12"), xaxt = "n")
lines(pr2, col = 2, lty = 1, type = "o")
lines(tl2, col = 4, lty = 2)
lines(tu2, col = 4, lty = 2)
axis(1, at = c(2017, 2018, 2019, 2020), labels = c("2017", "2018", "2019", "2020"))
abline(v = c(2017, 2018, 2019, 2020), lty = 3, col = 4)

# Visualize predictions for Model 3
plot(serie, xlim = c(2017, 2020), ylim = range(c(tl3, tu3, serie)),
     type = "o", col = 1, lty = 1, ylab = "Values", xlab = "Time",
     main = paste("Model ARIMA(0,1,1)(0,1,1)12"), xaxt = "n")
lines(pr3, col = 2, lty = 1, type = "o")
lines(tl3, col = 4, lty = 2)
lines(tu3, col = 4, lty = 2)
axis(1, at = c(2017, 2018, 2019, 2020), labels = c("2017", "2018", "2019", "2020"))
abline(v = c(2017, 2018, 2019, 2020), lty = 3, col = 4)

# Display Metrics
print(metrics, row.names = FALSE)
```

As you can see all of the models manage to predict the last year somewhat good, the differences in error metrics are extremely small but they exist. By comparing all the models, model 1, which is SARIMA(6,1,1)(0,1,1)<sub>12</sub> turns out to be the best. Additionally, the stability of all models can be affirmed, as the confidence intervals of the predictions remain well-behaved and do not widen excessively, indicating consistent performance and reliability over time.

## 3d.

In order to select the best model for forecasting we have to evaluate validation results, stability, and capability of prediction of all three candidate models. As we have seen earlier, all three candidate models are stable, model 1 shows the best error metrics, which means we only need to look at validation results. All three candidate models are similar in terms of the following things, which are: residuals plot, square Root of absolute residuals, histogram of residuals, ACF and PACF of residuals, and standardized residuals. The only differences between three candidate models can be seen in normal Q-Q plot and p-values for Ljung-Box test. In terms of the "best" normal Q-Q plot out of all candidate models, the model 3 has it. However, in terms of the "best" p-values for Ljung-Box test out of all candidate models, the model 1 has it. Since differences in normal Q-Q plots are negligible, we have to choose the model 3 as the best because its p-values for Ljung-Box test are the best. It is very important to note, that by saying the "best" we refer to the model and data we have, the "best" model is not necessarily the best in the absolute terms.


# 4. Predictions

## 4a.

The last thing we are going to do is obtain long term forecasts for the twelve months following the last observation available using the best model for forecasting

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
ultim <- c(2019, 12)
serie_train <- window(serie, end = ultim)
mod1B <- arima(serie_train, order = c(6, 1, 1), seasonal = list(order = c(0, 1, 1), period = 12))
pred1 <- predict(mod1B, n.ahead = 12)
pr1 <- ts(pred1$pred, start = ultim + c(0, 1), freq = 12)
se1 <- ts(pred1$se, start = ultim + c(0, 1), freq = 12)
tl1 <- pr1 - 1.96 * se1
tu1 <- pr1 + 1.96 * se1
ts.plot(serie, tl1, tu1, pr1, lty = c(1, 2, 2, 1), col = c(1, 4, 4, 2),
        xlim = c(2017, 2021), type = "o",
        main = paste("Model ARIMA(6,1,1)(0,1,1)12: Forecast for 2020-2021"))
abline(v = (2017:2021), lty = 3, col = 4)
forecast_results <- data.frame(
  Month = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"),
  Predicted = pr1,
  Lower_CI = tl1,
  Upper_CI = tu1
)
```

```{r, echo=FALSE}
print(forecast_results, row.names = FALSE)
```

By looking at the prediction in the future made by our best model we can affirm the stability of the model, as the confidence intervals of the predictions remain well-behaved and do not widen excessively, indicating consistent performance and reliability over time.
